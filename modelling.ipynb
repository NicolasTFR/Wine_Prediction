{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the data fram from scrapping.ipynb\n",
    "df=pd.read_csv(\"baseDF.csv\")\n",
    "df.drop(columns=\"Unnamed: 0\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First test set with limited columns to establish a baseline\n",
    "def Case1(regressor, dfCase1):\n",
    "\n",
    "## Features list on data we can directly use\n",
    "    features_list = ['vintage_wine_vintage_type', 'vintage_wine_is_natural', 'vintage_wine_taste_structure_acidity','vintage_wine_taste_structure_intensity', 'vintage_wine_taste_structure_sweetness','vintage_wine_taste_structure_tannin']\n",
    "\n",
    "    X = dfCase1.loc[:,features_list] \n",
    "    y = dfCase1.loc[:,\"vintage_wine_statistics_ratings_average\"] # target is the rating\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42) \n",
    "    numeric_features = [0,2,3,4,5]\n",
    "    numeric_transformer = StandardScaler()\n",
    "\n",
    "    categorical_features = [1] \n",
    "    categorical_transformer = OneHotEncoder()\n",
    "\n",
    "#preprocessing train set\n",
    "\n",
    "    feature_encoder = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical_features),    \n",
    "            ('num', numeric_transformer, numeric_features)\n",
    "            ]\n",
    "        )\n",
    "    X_train = feature_encoder.fit_transform(X_train)\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on training set\n",
    "    y_train_pred = regressor.predict(X_train)\n",
    "#Preprocessing test set\n",
    "    X_test = feature_encoder.transform(X_test)\n",
    "\n",
    "# Print R^2 scores\n",
    "    print(\"R2 score on training set : \", regressor.score(X_train, y_train))\n",
    "    print(\"R2 score on test set : \", regressor.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on training set :  0.2448545624042886\n",
      "R2 score on test set :  0.23643589741861992\n"
     ]
    }
   ],
   "source": [
    "#Baseline, testing case 1 with a linear regression\n",
    "regressor = LinearRegression()\n",
    "dfCase1= df\n",
    "Case1(regressor, dfCase1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so baseline with an R2 of 0.23, let's improve it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cleanregions(df):\n",
    "    #Clean the region names so we can do machine learning on it\n",
    "    \n",
    "    #Creating a second dataframe for this case\n",
    "    df2=df.copy()\n",
    "    \n",
    "    #Correcting the most common prefixes/suffixes to merge data names\n",
    "    df2['vintage_wine_region_name'] = df2['vintage_wine_region_name'].str.replace(' Villages', '')\n",
    "    df2['vintage_wine_region_name'] = df2['vintage_wine_region_name'].str.replace(' Premier Cru', '')\n",
    "    df2['vintage_wine_region_name'] = df2['vintage_wine_region_name'].str.replace(' Grand Cru', '')\n",
    "    df2['vintage_wine_region_name'] = df2['vintage_wine_region_name'].str.replace('Castillon - ', '')\n",
    "    df2['vintage_wine_region_name'] = df2['vintage_wine_region_name'].str.replace('Blaye - ', '')\n",
    "    \n",
    "    #Saint Emilion is written in a lot of different ways, harmonizing it to use it\n",
    "    #first boolean to detect if the line should be a saint emilion or not\n",
    "    has_emi = []\n",
    "    for x in df2['vintage_wine_region_name']:\n",
    "        if 'Saint-Émilion' in x:\n",
    "            has_emi.append(1)\n",
    "        else:\n",
    "            has_emi.append(0)\n",
    "    df2['emi'] = has_emi\n",
    "    #Rewriting all saint emilion lines in the same way\n",
    "    df2.loc[(df2.emi == 1 ),'vintage_wine_region_name']='Saint-Émilion'\n",
    "    #dropping the boolean we used\n",
    "    df2.drop(\"emi\", axis=1, inplace=True)\n",
    "    \n",
    "    #Removing the regions appearing less than 10 times\n",
    "    countregion=df2.groupby(\"vintage_wine_region_name\")[\"vintage_wine_name\"].count()\n",
    "    df2 = df2[df2['vintage_wine_region_name'].isin(countregion[countregion > 10].index)].copy()\n",
    "    \n",
    "    return df2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second test set which is the first set and the regions names\n",
    "def Case2(regressor, dfCase2):\n",
    "    ## Adding region name to the feature list\n",
    "    features_list = [\"vintage_wine_region_name\",'vintage_wine_vintage_type', 'vintage_wine_is_natural', 'vintage_wine_taste_structure_acidity','vintage_wine_taste_structure_intensity', 'vintage_wine_taste_structure_sweetness','vintage_wine_taste_structure_tannin',\"vintage_wine_statistics_ratings_count\"]\n",
    "\n",
    "    X = dfCase2.loc[:,features_list] \n",
    "    y = dfCase2.loc[:,\"vintage_wine_statistics_ratings_average\"] # target is the rating\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42) \n",
    "    numeric_features = [1,3,4,5,6,7] \n",
    "    numeric_transformer = StandardScaler()\n",
    "\n",
    "    categorical_features = [0,2] \n",
    "    categorical_transformer = OneHotEncoder()\n",
    "\n",
    "#preprocessing train set\n",
    "\n",
    "    feature_encoder = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical_features),    \n",
    "            ('num', numeric_transformer, numeric_features)\n",
    "            ]\n",
    "        )\n",
    "    X_train = feature_encoder.fit_transform(X_train)\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on training set\n",
    "    y_train_pred = regressor.predict(X_train)\n",
    "#Preprocessing test set\n",
    "    X_test = feature_encoder.transform(X_test)\n",
    "\n",
    "# Print R^2 scores\n",
    "    print(\"R2 score on training set : \", regressor.score(X_train, y_train))\n",
    "    print(\"R2 score on test set : \", regressor.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on training set :  0.66721748829355\n",
      "R2 score on test set :  0.6688552196124722\n"
     ]
    }
   ],
   "source": [
    "#Calculating case 2 with linear regression, adding the region name\n",
    "regressor = LinearRegression()\n",
    "Case2(regressor, Cleanregions(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R2 score goes up siginificantly to 0.66! Now using all columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test with all the features in the dataframe, auto detect if it's numerical or categorical\n",
    "def CaseAll(regressor, dfCase3):\n",
    "    ## Adding region name to the feature list\n",
    "    feature_list = [i for i in dfCase3.columns if i != 'vintage_wine_statistics_ratings_average' and i!=\"vintage_wine_winery_name\" and i!=\"vintage_wine_region_name\" and i!=\"vintage_wine_name\" and i!=\"vintage_name\"]\n",
    "    \n",
    "    X = dfCase3.loc[:,feature_list] \n",
    "    y = dfCase3.loc[:,\"vintage_wine_statistics_ratings_average\"] # target is the rating\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42) \n",
    "    #Select columns where type of data is numerical\n",
    "    query_cols1=X.select_dtypes(include=['number']).columns\n",
    "    #Get list of column indexes fitting previous test\n",
    "    numeric_features = [X.columns.get_loc(col) for col in query_cols1]\n",
    "    numeric_transformer = StandardScaler()\n",
    "\n",
    "    #Select columns where type of data is categorical\n",
    "    query_cols2=X.select_dtypes(include=['object']).columns\n",
    "    #Get list of column indexes fitting previous test\n",
    "    categorical_features = [X.columns.get_loc(col) for col in query_cols2]\n",
    "    categorical_transformer = OneHotEncoder()\n",
    "\n",
    "#preprocessing train set\n",
    "\n",
    "    feature_encoder = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical_features),    \n",
    "            ('num', numeric_transformer, numeric_features)\n",
    "            ]\n",
    "        )\n",
    "    X_train = feature_encoder.fit_transform(X_train)\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on training set\n",
    "    y_train_pred = regressor.predict(X_train)\n",
    "#Preprocessing test set\n",
    "    X_test = feature_encoder.transform(X_test)\n",
    "\n",
    "# Print R^2 scores\n",
    "    print(\"R2 score on training set : \", regressor.score(X_train, y_train))\n",
    "    print(\"R2 score on test set : \", regressor.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on training set :  0.4521056769086279\n",
      "R2 score on test set :  0.4739317659804927\n"
     ]
    }
   ],
   "source": [
    "regressor = LinearRegression()\n",
    "CaseAll(regressor,Cleanregions(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score is going down, we would need to clean outliers and take better care of the data to improve the score with a linear regressor\n",
    "Instead, we will try to go forward with other models to keep the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on training set :  0.8156302658646886\n",
      "R2 score on test set :  0.8066060409995337\n"
     ]
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=20, max_leaf_nodes=25,max_depth=9)\n",
    "CaseAll(regressor,Cleanregions(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R2 now at 0.8, we are on the right path!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now continuing our investigation, we will try to use the wine name, with the CountVectorizer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nicol\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "    # Getting a library of french stop words, to exclude them from the vectorizing and \n",
    "    #improve the relevance of the features\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding vectorized names to the dataframe\n",
    "def VectorizingName(df):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "#Count vectorizing name to split it into grams and test it for ML\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from nltk.corpus import stopwords\n",
    "    #losing in R² with grams of 3 and min df higher than 6, stopwords is an improvement\n",
    "    cv = CountVectorizer(ngram_range=(1,2), max_df= 1000, min_df=10, stop_words=stopwords.words('french'))\n",
    "    df3 = cv.fit_transform(df['vintage_wine_name'])\n",
    "    df3 = pd.DataFrame(df3.toarray(), columns=cv.get_feature_names_out())\n",
    "\n",
    "#Adding the previous columns\n",
    "\n",
    "    df3=pd.concat([df3, df.drop('vintage_wine_name', axis=1)], axis=1)\n",
    "\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on training set :  0.8181499606879179\n",
      "R2 score on test set :  0.8109905451668868\n"
     ]
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=20, max_leaf_nodes=25,max_depth=9)\n",
    "CaseAll(regressor,VectorizingName(Cleanregions(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, score is similar, but with unoptimized parameters, we will now optimize the models\n",
    "\n",
    "First without the names, to see which is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test with all the features in the dataframe, auto detect if it's numerical or categorical\n",
    "def GridSearch(dfCase3):\n",
    "    #Regressor is set, as it impacts the parameters\n",
    "    regressor = RandomForestRegressor()\n",
    "    ## Adding region name to the feature list\n",
    "    feature_list = [i for i in dfCase3.columns if i != 'vintage_wine_statistics_ratings_average' and i!=\"vintage_wine_winery_name\" and i!=\"vintage_wine_region_name\" and i!=\"vintage_wine_name\" and i!=\"vintage_name\"]\n",
    "    \n",
    "    X = dfCase3.loc[:,feature_list] \n",
    "    y = dfCase3.loc[:,\"vintage_wine_statistics_ratings_average\"] # target is the rating\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42) \n",
    "    #Select columns where type of data is numerical\n",
    "    query_cols1=X.select_dtypes(include=['number']).columns\n",
    "    #Get list of column indexes fitting previous test\n",
    "    numeric_features = [X.columns.get_loc(col) for col in query_cols1]\n",
    "    numeric_transformer = StandardScaler()\n",
    "\n",
    "    #Select columns where type of data is categorical\n",
    "    query_cols2=X.select_dtypes(include=['object']).columns\n",
    "    #Get list of column indexes fitting previous test\n",
    "    categorical_features = [X.columns.get_loc(col) for col in query_cols2]\n",
    "    categorical_transformer = OneHotEncoder()\n",
    "\n",
    "#preprocessing train and Test set\n",
    "\n",
    "    feature_encoder = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical_features),    \n",
    "            ('num', numeric_transformer, numeric_features)\n",
    "            ]\n",
    "        )\n",
    "    X_train = feature_encoder.fit_transform(X_train)\n",
    "    X_test = feature_encoder.transform(X_test)\n",
    "\n",
    "    params = {\n",
    "    'n_estimators':  [115],\n",
    "    'max_leaf_nodes': [165],\n",
    "    'max_depth': [9]\n",
    "        }\n",
    "    gridsearch = GridSearchCV(regressor, param_grid = params, cv = 5) # cv : the number of folds to be used for CV\n",
    "    gridsearch.fit(X_train, y_train)\n",
    "    print(\"Best hyperparameters : \", gridsearch.best_params_)\n",
    "    print(\"R2 score on training set : \", gridsearch.score(X_train, y_train))\n",
    "    print(\"R2 score on test set : \", gridsearch.score(X_test, y_test))\n",
    "    return gridsearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters :  {'max_depth': 7, 'max_leaf_nodes': 165, 'n_estimators': 115}\n",
      "R2 score on training set :  0.8513333408562684\n",
      "R2 score on test set :  0.829210136788451\n"
     ]
    }
   ],
   "source": [
    "gridsearch=GridSearch(Cleanregions(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~20 minutes \\\n",
    "Best hyperparameters :  {'max_depth': 7, 'max_leaf_nodes': 165, 'n_estimators': 115} \\\n",
    "R2 score on training set :  0.8513333408562684 \\\n",
    "R2 score on test set :  0.829210136788451 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters :  {'max_depth': 9, 'max_leaf_nodes': 165, 'n_estimators': 115}\n",
      "R2 score on training set :  0.877156418432801\n",
      "R2 score on test set :  0.8450551417947416\n"
     ]
    }
   ],
   "source": [
    "gridsearch2=GridSearch(VectorizingName(Cleanregions(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07878c45a9b18549480ac2f9ecb8f16bb7162456cf654f6757bcff1d6396abe7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
